# ZKP Verifiable AI

Regulators and industry alike are shifting from voluntary AI transparency pledges to enforceable obligations that demand evidence-backed assurances about how systems behave, comply with safety requirements, and respect rights. Verifiable AI responds to that shift by pairing policy narratives with cryptographic guarantees, replacing self-declared claims with independently auditable proofs that a model met a regulatory or contractual condition such as training provenance, data usage limits, or fairness constraints. This repo tracks that move “from principles to proofs,” translating the themes highlighted in recent legal-tech research into concrete experiments that show how zero-knowledge tooling can support regulatory-grade attestations.

Current focus areas:
- `research/` Literature notes, comparisons of frameworks, and distilled findings that track what’s happening across the field.
- `experiments/` Forthcoming hands-on trials using open-source models plus multiple ZKP frameworks to evaluate trade-offs in cost, accuracy, and prover/verifier ergonomics.

As the experiments mature, I’ll link the runnable configs, notebooks, and proof artifacts back to the relevant write-ups so the narrative stays cohesive.

